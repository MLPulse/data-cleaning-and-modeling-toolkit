{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c5c271",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "import mlflow\n",
    "import mlflow.sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de88930",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load raw data\n",
    "train_df = pd.read_csv('data/raw/Train.csv')\n",
    "test_df = pd.read_csv('data/raw/Test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfb7eb17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize missing data in the training dataset\n",
    "def visualize_missing_data(df):\n",
    "    missing_data = df.isnull().sum()\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    missing_data.plot(kind='bar')\n",
    "    plt.title('Missing Data in Each Column')\n",
    "    plt.xlabel('Columns')\n",
    "    plt.ylabel('Number of Missing Values')\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure(figsize=(14, 10))\n",
    "    sns.heatmap(df.isnull(), cbar=False, cmap='viridis')\n",
    "    plt.title('Heatmap of Missing Data')\n",
    "    plt.show()\n",
    "\n",
    "visualize_missing_data(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c13c017",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter data by missing values (keeping columns with <= 25% missing data)\n",
    "def filter_dataframe_by_missing_data(df, threshold=25):\n",
    "    missing_data = df.isnull().sum()\n",
    "    missing_data_percentage = (missing_data / len(df)) * 100\n",
    "    features_with_less_missing_data = missing_data_percentage[missing_data_percentage <= threshold].index.tolist()\n",
    "    filtered_df = df[features_with_less_missing_data]\n",
    "    return filtered_df\n",
    "\n",
    "filtered_train_df = filter_dataframe_by_missing_data(train_df)\n",
    "filtered_test_df = filter_dataframe_by_missing_data(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff14d35d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute missing values using a combination of simple and advanced methods\n",
    "class SafeLabelEncoder:\n",
    "    \"\"\"Custom LabelEncoder to handle unseen labels.\"\"\"\n",
    "    def __init__(self):\n",
    "        self.le = LabelEncoder()\n",
    "        self.classes_ = None\n",
    "\n",
    "    def fit(self, y):\n",
    "        self.le.fit(y)\n",
    "        self.classes_ = set(self.le.classes_)\n",
    "        return self\n",
    "\n",
    "    def transform(self, y):\n",
    "        return np.array([self.le.transform([label])[0] if label in self.classes_ else -1 for label in y])\n",
    "\n",
    "    def fit_transform(self, y):\n",
    "        self.fit(y)\n",
    "        return self.transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00d1089b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_imputation_models(filtered_train, num_rows=None):\n",
    "    if num_rows is None:\n",
    "        num_rows = len(filtered_train)\n",
    "\n",
    "    df = filtered_train.copy().iloc[:num_rows]\n",
    "    numeric_cols = [col for col in df.columns if df[col].dtype == 'float64' and df[col].nunique() > 5]\n",
    "    categorical_cols = [col for col in df.columns if col not in numeric_cols]\n",
    "\n",
    "    categorical_imputer = SimpleImputer(strategy='most_frequent')\n",
    "    df[categorical_cols] = categorical_imputer.fit_transform(df[categorical_cols])\n",
    "\n",
    "    label_encoders = {col: SafeLabelEncoder().fit(df[col]) for col in categorical_cols}\n",
    "    df[categorical_cols] = df[categorical_cols].apply(lambda col: label_encoders[col.name].transform(col))\n",
    "\n",
    "    regressors = {}\n",
    "    for col in numeric_cols:\n",
    "        if df[col].isnull().sum() > 0:\n",
    "            non_missing_data = df[~df[col].isnull()]\n",
    "            X_train = non_missing_data.drop(columns=[col])\n",
    "            y_train = non_missing_data[col]\n",
    "            regressor = RandomForestRegressor(n_estimators=100, n_jobs=-1, random_state=42)\n",
    "            regressor.fit(X_train, y_train)\n",
    "            regressors[col] = regressor\n",
    "\n",
    "    return categorical_imputer, label_encoders, regressors, categorical_cols, numeric_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b20f302",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_imputer, label_encoders, regressors, categorical_cols, numeric_cols = create_imputation_models(filtered_train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "245b0b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute missing data in the test set\n",
    "def impute_data(df, categorical_imputer, label_encoders, regressors, categorical_cols, numeric_cols, num_rows=None):\n",
    "    if num_rows is None:\n",
    "        num_rows = len(df)\n",
    "\n",
    "    df = df.iloc[:num_rows].copy(deep=True)\n",
    "    df[categorical_cols] = categorical_imputer.transform(df[categorical_cols])\n",
    "    for col in categorical_cols:\n",
    "        df[col] = label_encoders[col].transform(df[col])\n",
    "\n",
    "    for col in numeric_cols:\n",
    "        if df[col].isnull().sum() > 0:\n",
    "            missing_data = df[df[col].isnull()]\n",
    "            X_missing = missing_data.drop(columns=[col])\n",
    "            df.loc[df[col].isnull(), col] = regressors[col].predict(X_missing)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5a2c84a",
   "metadata": {},
   "outputs": [],
   "source": [
    "imputed_train_df = impute_data(filtered_train_df, categorical_imputer, label_encoders, regressors, categorical_cols, numeric_cols)\n",
    "imputed_test_df = impute_data(filtered_test_df, categorical_imputer, label_encoders, regressors, categorical_cols, numeric_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab660d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a decision tree model\n",
    "def train_model(train_df, selected_features):\n",
    "    X = train_df[selected_features]\n",
    "    y = train_df['target']\n",
    "\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    model = Pipeline(steps=[\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('regressor', DecisionTreeRegressor(random_state=42))\n",
    "    ])\n",
    "    \n",
    "    mlflow.set_experiment(\"decision-tree-regressor-experiment\")\n",
    "    \n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    y_pred_val = model.predict(X_val)\n",
    "    rmse_val = mean_squared_error(y_val, y_pred_val, squared=False)\n",
    "    mae_val = mean_absolute_error(y_val, y_pred_val)\n",
    "    r2_val = r2_score(y_val, y_pred_val)\n",
    "\n",
    "    mlflow.log_metric(\"rmse\", rmse_val)\n",
    "    mlflow.log_metric(\"mae\", mae_val)\n",
    "    mlflow.log_metric(\"r2\", r2_val)\n",
    "    mlflow.sklearn.log_model(model, \"Decision Tree Regression Model\")\n",
    "\n",
    "    print(f\"Validation RMSE: {rmse_val}\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f42d29bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features = [col for col in imputed_train_df.columns if col != 'target']\n",
    "trained_model = train_model(imputed_train_df, selected_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81b29250",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the model and log results\n",
    "def test_model(model, test_df, selected_features):\n",
    "    X_test = test_df[selected_features]\n",
    "    y_pred_test = model.predict(X_test)\n",
    "\n",
    "    results = pd.DataFrame({\n",
    "        'id': test_df['id'],\n",
    "        'predicted': y_pred_test\n",
    "    })\n",
    "    results.to_csv('data/processed/test_predictions.csv', index=False)\n",
    "    mlflow.log_artifact('data/processed/test_predictions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aadcc15d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model(trained_model, imputed_test_df, selected_features)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
